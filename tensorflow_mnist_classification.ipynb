{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dgoDKafKJmk"
      },
      "source": [
        "# Deep Neural Network for MNIST Classification\n",
        "\n",
        "MNIST provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image).\n",
        "\n",
        "The goal is to write a classification algorithm that detects which digit is written for the 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCkpHMxkKJmm"
      },
      "source": [
        "## Import the packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-datasets -q"
      ],
      "metadata": {
        "id": "F3LJOKMxK-mx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6XaXsTzeKJmm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds # TensorFLow includes a data provider for MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9ZJyZZXKJmn"
      },
      "source": [
        "## Load and Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tfds.load loads a dataset\n",
        "# mnist_dataset = tfds.load(name='mnist', as_supervised=True)\n",
        "# with_info=True provides a tuple containing information about the version, features, and number of samples\n",
        "# as_supervised=True will load the dataset in a 2-tuple structure (input, target)\n",
        "\n",
        "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
      ],
      "metadata": {
        "id": "MtUzku92L3nv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the training and testing dataset with the built references\n",
        "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
      ],
      "metadata": {
        "id": "L5i_3VenMB7P"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of validation samples as a % of the train samples\n",
        "num_validation_samples = tf.cast(0.1 * mnist_info.splits['train'].num_examples, tf.int64)"
      ],
      "metadata": {
        "id": "a_MaZ5ifMFrt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the number of test samples in a dedicated variable\n",
        "num_test_samples = tf.cast(mnist_info.splits['test'].num_examples, tf.int64)"
      ],
      "metadata": {
        "id": "cDc_3TFJMmlo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the inputs between 0 and 1\n",
        "def scale(image, label):\n",
        "  \"\"\"\n",
        "  function that scales an image and its label between 0 and 1\n",
        "  takes an image and a label as inputs\n",
        "  returns the image and its label with all its values between 0 and 1\n",
        "  \"\"\"\n",
        "  # typecast to float\n",
        "  image = tf.cast(image, tf.float32)\n",
        "\n",
        "  # Divide each element by 255 to get all elements between 0 and 1\n",
        "  image /= 255.\n",
        "\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "YM0WQfdwONRi"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the method .map() allows for custom transformation to a given dataset\n",
        "scaled_train_and_validation_data = mnist_train.map(scale)"
      ],
      "metadata": {
        "id": "h-5uxYGgOpRw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale and batch the test data\n",
        "test_data = mnist_test.map(scale)"
      ],
      "metadata": {
        "id": "abgkxmNtOylU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "# cannot shuffle the whole dataset in one go because it will not all fit in memory\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "# if BUFFER_SIZE=1 => no shuffling will actually happen\n",
        "# if BUFFER_SIZE >= num samples => shuffling is uniform\n",
        "\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n"
      ],
      "metadata": {
        "id": "CvKPuZUDO1ED"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a batch with a batch size equal to the total number of validation samples\n",
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)"
      ],
      "metadata": {
        "id": "791kjCFrQ3OP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the train_data is everything else\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)"
      ],
      "metadata": {
        "id": "blh51OEdQ9W-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the batch size\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "tfv4Lv-4RB4g"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch the train data\n",
        "train_data = train_data.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "vS6M39JlRJXT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch the validation data\n",
        "validation_data = validation_data.batch(num_validation_samples)"
      ],
      "metadata": {
        "id": "UjFneEQaRNAv"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch the test data\n",
        "test_data = test_data.batch(num_test_samples)"
      ],
      "metadata": {
        "id": "KHzGGoV0RTAU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes next batch\n",
        "# as_supervized=True for a 2-tuple structure\n",
        "validation_inputs, validation_targets = next(iter(validation_data))"
      ],
      "metadata": {
        "id": "WKmFOYJkRfpM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw7sl_8zKJmp"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose parameters\n",
        "input_size = 784\n",
        "output_size = 10\n",
        "hidden_layer_size = 50"
      ],
      "metadata": {
        "id": "o-0cNbNPR9Uk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "16AOPshHKJmp"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "    # the first layer (the input layer)\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\n",
        "\n",
        "    # tf.keras.layers.Dense is implementing: output = activation(dot(input, weight) + bias)\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
        "\n",
        "    # the final layer is activated with softmax\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--NyqMKwKJmp"
      },
      "source": [
        "### Choose the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "AQuZFrjnKJmq"
      },
      "outputs": [],
      "source": [
        "# compile the model with the adam optimizer, sparse categorical cross entropy loss function, and accuracy metric\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcZPxTSIKJmq"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the maximum number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "PWD-z4JoSlci"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTDzDhUWKJms",
        "outputId": "6ea7ff31-ea9a-47b5-e851-b2d0cac9f125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 - 10s - 6ms/step - accuracy: 0.9130 - loss: 0.3031 - val_accuracy: 0.9488 - val_loss: 0.1666\n",
            "Epoch 2/10\n",
            "1688/1688 - 5s - 3ms/step - accuracy: 0.9586 - loss: 0.1383 - val_accuracy: 0.9652 - val_loss: 0.1184\n",
            "Epoch 3/10\n",
            "1688/1688 - 4s - 3ms/step - accuracy: 0.9690 - loss: 0.1030 - val_accuracy: 0.9713 - val_loss: 0.0920\n",
            "Epoch 4/10\n",
            "1688/1688 - 4s - 2ms/step - accuracy: 0.9741 - loss: 0.0849 - val_accuracy: 0.9743 - val_loss: 0.0902\n",
            "Epoch 5/10\n",
            "1688/1688 - 5s - 3ms/step - accuracy: 0.9776 - loss: 0.0720 - val_accuracy: 0.9778 - val_loss: 0.0780\n",
            "Epoch 6/10\n",
            "1688/1688 - 4s - 2ms/step - accuracy: 0.9807 - loss: 0.0612 - val_accuracy: 0.9792 - val_loss: 0.0702\n",
            "Epoch 7/10\n",
            "1688/1688 - 4s - 2ms/step - accuracy: 0.9823 - loss: 0.0551 - val_accuracy: 0.9827 - val_loss: 0.0629\n",
            "Epoch 8/10\n",
            "1688/1688 - 5s - 3ms/step - accuracy: 0.9855 - loss: 0.0473 - val_accuracy: 0.9825 - val_loss: 0.0566\n",
            "Epoch 9/10\n",
            "1688/1688 - 4s - 2ms/step - accuracy: 0.9870 - loss: 0.0427 - val_accuracy: 0.9855 - val_loss: 0.0520\n",
            "Epoch 10/10\n",
            "1688/1688 - 4s - 2ms/step - accuracy: 0.9878 - loss: 0.0380 - val_accuracy: 0.9822 - val_loss: 0.0581\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7931560a16c0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# train the model\n",
        "model.fit(train_data, validation_data=(validation_inputs, validation_targets), epochs=NUM_EPOCHS, verbose = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT9nosQOKJms"
      },
      "source": [
        "## Test the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rFMgpkLKJms",
        "outputId": "5ed5ed74-747f-4144-8645-3d230f53caf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933ms/step - accuracy: 0.9701 - loss: 0.1095\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIiMXoR6KJmt",
        "outputId": "255085e2-a822-4ad2-d5ae-5f62fd6f91e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.11. Test accuracy: 97.01%\n"
          ]
        }
      ],
      "source": [
        "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:py3-TF2.0]",
      "language": "python",
      "name": "conda-env-py3-TF2.0-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}